{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 ... searching gas stations and fetching data \n",
    "\n",
    "about them and about the peak hours.\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "As a first step, I use publicly available data about the capacity use of the gas stations on Google maps (peak times). To do this, I fetching all gas station place IDs (and further values) of all districts using the google place API. With this IDs, I visit the Google Maps website and read out the data for the peak hours for each gas station. I fill a Postgresql database with all the data obtained. The evaluations can then be done later via the database.\n",
    "\n",
    "![FlowChart](https://github.com/cbrennig/peak-hours-and-high-power-charging/blob/main/jupyter_notebooks/images/flowchart.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import psycopg2\n",
    "from credentials import Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database class\n",
    "\n",
    "As in part one, the connection to the database is established when a database instance is called. The necessary credentials are in the file ``credentials.py``. The database class is there to \n",
    "\n",
    "1. return district names (which have not yet been entered)\n",
    "\n",
    "2. record data from the Place API call (place id, address, name, type, geolocation data etc)\n",
    "\n",
    "3. map address data and types to the corresponding n:m tables\n",
    "\n",
    "4. record previously unrecorded types into the appropriate table and process their IDs for subsequent records\n",
    "\n",
    "5. record peak times into the database.\n",
    "\n",
    "\n",
    "I will not use docstrings here, as the tasks of the individual functions are easy to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GasStationDB(Credentials):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conn = psycopg2.connect(dbname=self.DBNAME, user=self.DBUSER, password=self.DBPASS)\n",
    "        self.cur = self.conn.cursor() \n",
    "        \n",
    "    def _get_station_id(self, place):\n",
    "        query = \"SELECT * FROM portfolio.stations WHERE place_id = '{}';\".format(place['place_id'])\n",
    "        self.cur.execute(query)\n",
    "        result = self.cur.fetchone()\n",
    "        if result:\n",
    "            return result[0]\n",
    "        return None\n",
    "    \n",
    "    def _get_zip_id(self, zip_code):\n",
    "        self.cur.execute(\"SELECT * FROM portfolio.zip_codes WHERE zip_code = '{}';\".format(zip_code))\n",
    "        try:\n",
    "            return self.cur.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            return False\n",
    "        \n",
    "    def _get_types_id(self, name):\n",
    "        self.cur.execute(\"SELECT * FROM portfolio.types WHERE name = '{}';\".format(name))\n",
    "        result = self.cur.fetchone()\n",
    "        try:\n",
    "            return result[0]\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def _populate_station_data(self, place):\n",
    "        cmd = \"\"\"INSERT INTO portfolio.stations\n",
    "                        (name, address, place_id, global_plus_code, location_lat, location_lng,\n",
    "                         location_viewport_northeast_lat, location_viewport_northeast_lng,\n",
    "                         location_viewport_southwest_lat, location_viewport_southwest_lng,\n",
    "                         business_status) VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s );                              \n",
    "              \"\"\"\n",
    "        attr_list = ['name', 'address', 'place_id', 'global_plus_code', 'location_lat', 'location_lng',\n",
    "                     'location_viewport_northeast_lat', 'location_viewport_northeast_lng', \n",
    "                     'location_viewport_southwest_lat', 'location_viewport_southwest_lng',\n",
    "                     'business_status']\n",
    "        values_list = []\n",
    "        for attr in attr_list:\n",
    "            values_list.append(place[attr]) \n",
    "\n",
    "        self.cur.executemany(cmd, [values_list])\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def _populate_guest_quantity_data(self, data):             \n",
    "        cmd = \"\"\"INSERT INTO portfolio.guest_quantities\n",
    "                        (station_id, weekday, hr00, hr01, hr02, hr03, hr04, hr05, hr06, hr07, hr08, hr09, \n",
    "                        hr10, hr11, hr12, hr13, hr14, hr15, hr16, hr17, hr18, hr19, hr20, hr21, hr22, hr23\n",
    "                        ) VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s );              \n",
    "              \"\"\"\n",
    "        self.cur.executemany(cmd, data)\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _populate_station_zip_table(self, data):\n",
    "        cmd = \"\"\"INSERT INTO portfolio.station_zip\n",
    "                        (zds_station_id, zds_zip_id)\n",
    "                        VALUES ( %s, %s );\n",
    "              \"\"\"\n",
    "        self.cur.execute(cmd, data)\n",
    "        self.conn.commit()\n",
    "        \n",
    "    def _populate_types_table(self, data):\n",
    "        cmd = \"\"\"INSERT INTO portfolio.types\n",
    "                        (name) VALUES ( %s );\n",
    "              \"\"\"\n",
    "        self.cur.execute(cmd, [data])\n",
    "        self.conn.commit()\n",
    "        \n",
    "    def _populate_station_type_table(self, data):\n",
    "        cmd = \"\"\"INSERT INTO portfolio.type_place\n",
    "                        (ts_types_id, ts_stations_id) VALUES ( %s, %s );\n",
    "              \"\"\"\n",
    "        self.cur.executemany(cmd, data)\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Maps class\n",
    "\n",
    "This class contains the functions to grab the maps web pages using Selenium webdriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchGMaps:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initialise the webdriver\n",
    "        \"\"\"\n",
    "        self.html_string = ''\n",
    "        self.base_url = 'https://www.google.com/maps/place/?q=place_id:'\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    def accessing_google(self):\n",
    "        \"\"\"\n",
    "        establishing a connection to google maps\n",
    "        accept cookies if not already done\n",
    "        :return: str message\n",
    "        \"\"\"\n",
    "        any_place_id = 'ChIJvTkT0OWApEcRHkO3-fc99Ks'\n",
    "        url = self.base_url + any_place_id\n",
    "        self.driver.get(url)\n",
    "        try:\n",
    "            cookies_accept_button = '/html/body/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div/div/button'\n",
    "            self.driver.find_element_by_xpath(cookies_accept_button).click()\n",
    "            time.sleep(1)\n",
    "            return 'connected'\n",
    "        except Exception as e:\n",
    "            time.sleep(1)\n",
    "            return 'already connected '+self.driver.title\n",
    "        \n",
    "    def browse_site_by_place_id(self, place_id):\n",
    "        \"\"\"\n",
    "        getting the full website content\n",
    "        :param place_id: previously obtained id for the location to be called up\n",
    "        :return: True or False\n",
    "        \"\"\"\n",
    "        url = self.base_url + place_id\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            self.content = self.driver.page_source\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "    def get_html_string(self):\n",
    "        \"\"\"\n",
    "        making a single string of the website content in order to simplify\n",
    "        matching the data string inside the js code\n",
    "        :return: True or False\n",
    "        \"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(self.content, 'html.parser')\n",
    "            html_content_list = str(soup).split('\\n')\n",
    "            self.html_string = ' '.join(html_content_list)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place class\n",
    "\n",
    "This class contains the functions to fetch the place details. For this purpose, the google place api is used. A brief description of each function can be found in the individual docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlacesAPI:\n",
    "    \n",
    "    def __init__(self, search_term):\n",
    "        \"\"\"\n",
    "        load the API key and create the request string for one session \n",
    "        with up to two next page loads\n",
    "        :param search_term: str\n",
    "        \"\"\"\n",
    "        with open('/home/offboss/credentials/places_api_key.txt', 'r') as f:\n",
    "            API_KEY = f.read()\n",
    "        self.API_KEY = '&key=' + API_KEY\n",
    "        \n",
    "        url = 'https://maps.googleapis.com/maps/api/place/'\n",
    "        find_place_request = 'textsearch/'\n",
    "        output_type = 'json?query='\n",
    "        search_term = search_term.replace(' ', '%20')\n",
    "        place_type = 'gas_station'\n",
    "        self.location_request = url  + find_place_request + output_type + search_term + self.API_KEY\n",
    "        self.next_page_token = ''\n",
    "        \n",
    "    def query_results(self):\n",
    "        \"\"\"\n",
    "        request the search results via place api\n",
    "        and load the next page token if one is delivered\n",
    "        :return: result part of the api response\n",
    "        \"\"\"\n",
    "        result = requests.get(self.location_request + self.next_page_token)\n",
    "        if result.status_code != 200:\n",
    "            return False\n",
    "        try:\n",
    "            self.next_page_token = \"&pagetoken=\" + result.json()['next_page_token']\n",
    "        except Exception as e:\n",
    "            self.next_page_token = False\n",
    "            \n",
    "        return result.json()['results']\n",
    "\n",
    "    def get_places_data(self, result):\n",
    "        \"\"\"\n",
    "        read all relevant data from the json response\n",
    "        all error exceptions where put into the code while testing\n",
    "        :param result: api response result (json)\n",
    "        :return: places - list of dictionaries to populate the stations table\n",
    "        \"\"\"\n",
    "        places = [] \n",
    "        for place in result:\n",
    "            p = {'name': place['name']} \n",
    "            p['address'] = place['formatted_address'] \n",
    "            p['place_id'] = place['place_id'] \n",
    "            p['reference'] = place['reference'] \n",
    "            try:\n",
    "                p['global_plus_code'] = place['plus_code']['global_code'] \n",
    "            except:\n",
    "                p['global_plus_code'] = None\n",
    "            p['location_lat'] = place['geometry']['location']['lat'] \n",
    "            p['location_lng'] = place['geometry']['location']['lng']\n",
    "            p['location_viewport_northeast_lat'] = place['geometry']['viewport']['northeast']['lat']\n",
    "            p['location_viewport_northeast_lng'] = place['geometry']['viewport']['northeast']['lng']\n",
    "            p['location_viewport_southwest_lat'] = place['geometry']['viewport']['southwest']['lat']\n",
    "            p['location_viewport_southwest_lng'] = place['geometry']['viewport']['southwest']['lng']\n",
    "            p['types'] = place['types']\n",
    "            try:\n",
    "                p['business_status'] = place['business_status']\n",
    "            except:\n",
    "                p['business_status'] = None\n",
    "            places.append(p)\n",
    "        return places       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing class\n",
    "\n",
    "The functions of this class are there to extract the data from Maps web pages. On the one hand, the web page source code is parsed in such a way that the decisive places with the data are exposed. Afterwards, the data is prepared in such a way that it can be loaded into the corresponding table. In addition to this primary job, other smaller data cleaning tasks are also executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomiseData:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_string = ''\n",
    "        self.data = []\n",
    "    \n",
    "    def _no_data(self):\n",
    "        \"\"\"\n",
    "        creates a dataset with None values for the websites \n",
    "        from which no peak hours were returned\n",
    "        :return: no_data - list of 24times [hour, None]\n",
    "        \"\"\"\n",
    "        no_data = [[None for i in range(24)] for x in range(7)]\n",
    "        i=1\n",
    "        for item in no_data:\n",
    "            item.insert(0, i)\n",
    "            i+=1\n",
    "        return no_data \n",
    "    \n",
    "    def _add_station_id(self, station_id, data):\n",
    "        \"\"\"\n",
    "        add the stations id to the peak hours dataset\n",
    "        :param station_id: int\n",
    "        :param data: peak hours dataset\n",
    "        :return: data\n",
    "        \"\"\"\n",
    "        for item in data:\n",
    "            item.insert(0, station_id)\n",
    "        return data\n",
    "    \n",
    "    def _get_zip_code(self, place):\n",
    "        \"\"\"\n",
    "        get the zip code out of the address from the place api response\n",
    "        :param place: dict dataset of a station\n",
    "        :return: str of 5 digits\n",
    "        \"\"\"\n",
    "        return re.findall(r'[0-9]{5}', place['address'])[0]\n",
    "    \n",
    "    def get_data_string(self, html_string):\n",
    "        \"\"\"\n",
    "        find data string \n",
    "        it is within the script part of the website\n",
    "        :param html_string: single line str\n",
    "        :return: True or False\n",
    "        \"\"\"\n",
    "        self.data_string = ''\n",
    "        start_pattern = r'\\[+[0-9],\\[+[0-9]'\n",
    "        mid_pattern = r'(.*?)'\n",
    "        end_pattern = r'\\]+,[0-9]\\]+,[0-9]'\n",
    "        mask = start_pattern + mid_pattern + end_pattern\n",
    "        try:\n",
    "            self.data_string = '7,[[4' + re.search(mask, html_string).group(1) + ']],0]],6'\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        extracting the data from the data string\n",
    "        and prepare a dataset for populating the \n",
    "        guest_quantities table\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        \n",
    "        def _cleanup(values):\n",
    "            value_set = []\n",
    "            for value in values:\n",
    "                val = re.sub(r'\\[+', '', value).split(',')\n",
    "                if len(val)== 3:\n",
    "                    del val[2]\n",
    "                value_set.append(val)\n",
    "            return value_set\n",
    "        \n",
    "        def _change_dtype(dlist):\n",
    "            return [[int(item[0]), int(item[1])] for item in dlist]\n",
    "        \n",
    "        def _append_missing_hours_data():\n",
    "            hours = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, \n",
    "                     12:0, 13:0, 14:0, 15:0, 16:0, 17:0, 18:0, 19:0, 20:0, 21:0, 22:0, 23:0}\n",
    "            new_list = []\n",
    "            for day in self.data:\n",
    "                for pair in day[1]:\n",
    "                    hours[pair[0]] = pair[1]\n",
    "                sub_list = [[k, v] for k, v in hours.items()]\n",
    "                new_day = [day[0]]\n",
    "                new_day.append(sub_list)\n",
    "                new_list.append(new_day)\n",
    "            self.data = new_list\n",
    "        \n",
    "        def _sorted_data():\n",
    "            sorted_data = []\n",
    "            for item in self.data:\n",
    "                item[1].sort()\n",
    "                dataset = [x[1] for x in item[1]]\n",
    "                dataset.insert(0, item[0])\n",
    "                sorted_data.append(dataset)\n",
    "            return sorted_data\n",
    "                \n",
    "        split_pattern = r']+,[0-9]],\\['\n",
    "        datasets = re.split(split_pattern, self.data_string)\n",
    "        \n",
    "        match_pattern = r'\\[+[0-9]+,[0-9]+,'\n",
    "        for dataset in datasets:\n",
    "            values = _cleanup(re.findall(match_pattern, str(dataset[1:])))\n",
    "            self.data.append([int(dataset[0]), _change_dtype(values)])\n",
    "        _append_missing_hours_data()\n",
    "        self.data = _sorted_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main class\n",
    "\n",
    "The main class is responsible for maintaining the order of the individual tasks. As shown in the graphic above, a search query is first executed with the given search term. The answers returned by the API (search results) are successively transferred to the database and the respective peak time data is obtained. For each individual location, the Maps page is accessed and a check is made to see whether the peak time data is available or not. If they are available, they are processed accordingly. If not, a no-data record is created for this location. As soon as all search results have been processed, the next page of the API is called up or a new search query is started. Google place API delivers a maximum of 20 search results per call. These can be extended by up to two additional \"pages\". For this purpose, a so-called next-page-token is supplied. However, each page cost a request credit. \n",
    "All places that have already been included in the database are not recorded any further. I have tried to avoid as many errors as possible; at the same time I have tried to keep the number of exceptions low in order not to store too many no-data responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainPile:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initialise further classes\n",
    "        \"\"\"\n",
    "        self.FGM = FetchGMaps()\n",
    "        print(self.FGM.accessing_google())\n",
    "        self.GDB = GasStationDB()\n",
    "        self.CD = CustomiseData()\n",
    "        self.counter = 0 \n",
    "\n",
    "    def fetch_places(self, search_term='Tankstelle in Berlin'):\n",
    "        \"\"\"\n",
    "        main function to fetch places via the place API\n",
    "        :param search_term: str\n",
    "        \"\"\"\n",
    "        PA = PlacesAPI(search_term)\n",
    "        while True:\n",
    "            if PA.next_page_token is not False:\n",
    "                results = PA.query_results()\n",
    "                if results is not False:\n",
    "                    places = PA.get_places_data(results)\n",
    "                    \n",
    "                    for place in places:\n",
    "                        self.counter += 1\n",
    "                        \n",
    "                        # check whether the station is recorded or not in table 'stations'\n",
    "                        if not self.GDB._get_station_id(place):\n",
    "                        \n",
    "                            # populate station data\n",
    "                            self.GDB._populate_station_data(place)\n",
    "                            \n",
    "                            # populate n:m table with zip_station data\n",
    "                            zip_code = self.CD._get_zip_code(place)\n",
    "                            station_id = self.GDB._get_station_id(place)\n",
    "                            zip_id = self.GDB._get_zip_id(zip_code)\n",
    "                            self.GDB._populate_station_zip_table([station_id, zip_id])\n",
    "                            \n",
    "                            # populate types data\n",
    "                            type_ids = []\n",
    "                            for type_name in place['types']:\n",
    "                                # check if the type name already exists\n",
    "                                if not self.GDB._get_types_id(type_name):\n",
    "                                    # populate type_name\n",
    "                                    self.GDB._populate_types_table(type_name) # <======= ??? \n",
    "                                else:\n",
    "                                    #print('already exists in db')\n",
    "                                    pass\n",
    "                                #getting type_name id and collect in list\n",
    "                                type_ids.append(self.GDB._get_types_id(type_name))\n",
    "                            #print('type ids: ', type_ids)\n",
    "                                \n",
    "                            # populate station_type table with\n",
    "                            # station_id and list of type ids\n",
    "                            station_types_data = [[type_id, station_id] for type_id in type_ids]\n",
    "                            self.GDB._populate_station_type_table(station_types_data)\n",
    "                                \n",
    "                            # start processing guest quantity data\n",
    "                            self.fetch_quantities(place)\n",
    "                        else:\n",
    "                            print('station {} {} already populated'.format(place['name'], place['address']))\n",
    "                else:\n",
    "                    print('no more places found within this search')\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    def fetch_quantities(self, place):\n",
    "        \"\"\"\n",
    "        main function to fetch peak hours of a place/station\n",
    "        :param place: dict dataset of a station\n",
    "        \"\"\"\n",
    "        print('')\n",
    "        print('=========================== {} ============================'.format(self.counter))\n",
    "        print(place['name'], place['address'])\n",
    "        print('-----------------------------------------------------------')\n",
    "\n",
    "        if self.FGM.browse_site_by_place_id(place['place_id']):\n",
    "            if self.FGM.get_html_string():\n",
    "                if self.CD.get_data_string(self.FGM.html_string): \n",
    "                    self.CD.get_data()\n",
    "                else:\n",
    "                    print('get_data_string failed')\n",
    "                    self.CD.data = self.CD._no_data() \n",
    "                                        \n",
    "                # add new station_id to data\n",
    "                self.CD.data = self.CD._add_station_id(self.GDB._get_station_id(place), self.CD.data)\n",
    "                \n",
    "                # populate DB\n",
    "                self.GDB._populate_guest_quantity_data(self.CD.data) \n",
    "            \n",
    "            else:\n",
    "                print('get_html_string failed')\n",
    "        else:\n",
    "            print('browse_site_by_place_id failed') \n",
    "        print()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### connect database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDB = GasStationDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed the search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify already recorded districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT dist_name FROM portfolio.districts \n",
    "                 WHERE district_id IN (\n",
    "                      SELECT district_id FROM portfolio.zip_codes \n",
    "                            WHERE zip_id IN (\n",
    "                                 SELECT zds_zip_id FROM portfolio.station_zip\n",
    "                                  ));\n",
    "        \"\"\"\n",
    "GDB.cur.execute(query)\n",
    "results = GDB.cur.fetchall()\n",
    "district_names = [district_name[0] for district_name in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get not recorded district names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDB = GasStationDB()\n",
    "if len(district_names) > 0:\n",
    "    query = \"\"\"SELECT dist_name FROM portfolio.districts WHERE dist_name NOT IN (\n",
    "               SELECT dist_name FROM portfolio.districts \n",
    "                 WHERE district_id IN (\n",
    "                      SELECT district_id FROM portfolio.zip_codes \n",
    "                            WHERE zip_id IN (\n",
    "                                 SELECT zds_zip_id FROM portfolio.station_zip\n",
    "                                  )));\n",
    "        \"\"\"\n",
    "else:\n",
    "    query = \"SELECT dist_name FROM portfolio.districts;\"\n",
    "GDB.cur.execute(query)\n",
    "table = GDB.cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start fetching data and populating DB\n",
    "### Creating search term and start searching by district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching: Tankstelle in Adlershof\n",
      "connected\n",
      "\n",
      "=========================== 1 ============================\n",
      "HEM Tankstelle Adlergestell 305, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "=========================== 2 ============================\n",
      "JET Tankstelle Glienicker Weg 105, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "=========================== 3 ============================\n",
      "Elan-Tankstelle Adlergestell 179, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "=========================== 4 ============================\n",
      "AGIP Adlergestell Adlergestell 289, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "=========================== 5 ============================\n",
      "Autogas Adlershof Glienicker Weg 105-107, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "get_data_string failed\n",
      "\n",
      "\n",
      "=========================== 6 ============================\n",
      "Uwe Werkstatt Rudower Ch 44, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "get_data_string failed\n",
      "\n",
      "\n",
      "=========================== 7 ============================\n",
      "Ladesäule be-emobil 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "get_data_string failed\n",
      "\n",
      "\n",
      "=========================== 8 ============================\n",
      "MietFirma - MietHänger | MietStation AGIP-Tankstelle Adlershof Adlergestell 289, 12623 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "get_data_string failed\n",
      "\n",
      "\n",
      "=========================== 9 ============================\n",
      "CleanCar AG Glienicker Weg 182, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "\n",
      "station TotalEnergies Tankstelle Oberspreestraße 138, 12555 Berlin, Germany already populated\n",
      "\n",
      "=========================== 11 ============================\n",
      "MietFirma - MietHänger und MietDachboxen | MietStation ELAN-Tankstelle Adlergestell 179, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "browse_site_by_place_id failed\n",
      "\n",
      "\n",
      "=========================== 12 ============================\n",
      "Bft Bau GmbH Arndtstraße 1, 12489 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "browse_site_by_place_id failed\n",
      "\n",
      "\n",
      "=========================== 13 ============================\n",
      "Star Adlergestell 121, 12439 Berlin, Germany\n",
      "-----------------------------------------------------------\n",
      "browse_site_by_place_id failed\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ddb58b244d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'searching: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mBC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_places\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFGM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0a22b715c9cc>\u001b[0m in \u001b[0;36mfetch_places\u001b[0;34m(self, search_term)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                             \u001b[0;31m# start processing guest quantity data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_quantities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'station {} {} already populated'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0a22b715c9cc>\u001b[0m in \u001b[0;36mfetch_quantities\u001b[0;34m(self, place)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'browse_site_by_place_id failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for district in table[:50]:\n",
    "    search_term = \"Tankstelle in {}\".format(district[0])\n",
    "    print('searching: {}'.format(search_term))\n",
    "    MP = MainPile()\n",
    "    MP.fetch_places(search_term)\n",
    "    MP.FGM.driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### close db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDB.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Most of the data were automatically collected by the predefined algorithm, i.e. on the basis of the district names that had already been stored in the database. In addition to the search queries by district name, manually created lists (motorway numbers and cities with more than 90,000 inhabitants) were added to the search query and processed. I did this to ensure that the desired locations on motorways and near metropolitan areas were included in every case.\n",
    "\n",
    "Besides some error exceptions due to missing or incorrect values in the place api and some non-fetchable maps pages, the data collection went pretty well. Unfortunately, the quota for the API calls was not large enough to achieve even tighter coverage. This is also the reason for the additional search lists mentioned earlier. \n",
    "\n",
    "\n",
    "### Some personal reflexions\n",
    "- ever stop the chromedriver, otherwise it leads to a buffer overflow\n",
    "- next time use a pipeline model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
